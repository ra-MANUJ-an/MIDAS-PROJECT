{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_task1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTebOpA4jc4t92fpNtw7cQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra-MANUJ-an/MIDAS-PROJECT/blob/main/Project_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGmNTjuwhsIu"
      },
      "source": [
        "**IMPORTS**\n",
        "\n",
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy6usVcHX3s9",
        "outputId": "a6e9f24b-fde4-47fe-88a8-ec51f5a8fac0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile # extracting zip files\n",
        "import random # shuffling images\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import h5py\n",
        "import math\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)\n",
        "import gzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKJuKrRlh2FP"
      },
      "source": [
        "**RESNET UTILITIES**\n",
        "\n",
        "taken from : https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/resnets_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTuRGCMYuFW"
      },
      "source": [
        "#resnets_utils.py\n",
        "\n",
        "def load_dataset(): \n",
        "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "    \n",
        "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "    \n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    m = X.shape[0]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation,:,:,:]\n",
        "    shuffled_Y = Y[permutation,:]\n",
        "    \n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    return mini_batches\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "    \n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    \n",
        "    return Z3\n",
        "    \n",
        "def predict(X, parameters):\n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "         \n",
        "    return prediction "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R468u2175m-"
      },
      "source": [
        "Extracting Files from \"trainPart1.zip\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf2Xcu169XHv",
        "outputId": "9c2ad5d5-4e9f-4aaa-f8d3-ec1b0f80178e"
      },
      "source": [
        "file_name = \"trainPart1.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip :\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHextMC9BqG"
      },
      "source": [
        "DATADIRECTORY = \"/content/train\"\n",
        "CATEGORIES = [\"Sample001\", \"Sample002\", \"Sample003\", \"Sample004\", \"Sample005\", \"Sample006\", \"Sample007\", \"Sample008\", \"Sample009\", \"Sample010\",\n",
        " \"Sample011\", \"Sample012\", \"Sample013\", \"Sample014\", \"Sample015\", \"Sample016\", \"Sample017\", \"Sample018\", \"Sample019\", \"Sample020\",\n",
        " \"Sample021\", \"Sample022\", \"Sample023\", \"Sample024\", \"Sample025\", \"Sample036\", \"Sample027\", \"Sample028\", \"Sample029\", \"Sample030\",\n",
        " \"Sample031\", \"Sample032\", \"Sample033\", \"Sample034\", \"Sample035\", \"Sample036\", \"Sample037\", \"Sample038\", \"Sample039\", \"Sample040\",\n",
        " \"Sample041\", \"Sample042\", \"Sample043\", \"Sample044\", \"Sample045\", \"Sample046\", \"Sample047\", \"Sample048\", \"Sample049\", \"Sample050\",\n",
        " \"Sample051\", \"Sample052\", \"Sample053\", \"Sample054\", \"Sample055\", \"Sample056\", \"Sample057\", \"Sample058\", \"Sample059\", \"Sample060\",\n",
        " \"Sample061\", \"Sample062\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9mPzuTYEyL"
      },
      "source": [
        "classSize = len(CATEGORIES)\n",
        "print(classSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb2kBuOIJimp"
      },
      "source": [
        "IMG_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnOaPz7bJoFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4713bb-4ccb-47f7-e010-27239499bb18"
      },
      "source": [
        "trainingData = []\n",
        "\n",
        "def createTrainingData():\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(DATADIRECTORY,category)\n",
        "        classNum = CATEGORIES.index(category)  # get the classification\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            try:\n",
        "                imgArray = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                newArray = cv2.resize(imgArray, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                trainingData.append([newArray, classNum])  # add this to our trainingData\n",
        "            except Exception as e:  # keeps output cleans\n",
        "                pass\n",
        "\n",
        "createTrainingData()\n",
        "print(len(trainingData))\n",
        "\n",
        "random.shuffle(trainingData)\n",
        "# we are shuffling the data so that classifier does not \n",
        "# look at same type of images for a long time\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in trainingData :\n",
        "  X.append(features)\n",
        "  y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:00<00:00, 89.59it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.42it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.14it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.96it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.08it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 85.76it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.25it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.67it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 86.60it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.30it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.11it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 86.23it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.73it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.02it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 86.40it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 85.72it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.75it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.65it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.73it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.88it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 93.14it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.75it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 92.19it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 93.95it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.97it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.77it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.87it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.64it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 85.92it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.94it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.39it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 94.35it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.87it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 94.10it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.50it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 85.68it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.93it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.52it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.16it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.41it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.77it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.50it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.55it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.54it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.02it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 92.94it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.22it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.51it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.25it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.24it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.13it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.04it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.49it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.23it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.60it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 88.37it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 92.61it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.08it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 90.21it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 91.36it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.41it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 87.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOeQWnfkiJ0L"
      },
      "source": [
        "**SMALL RESIDUAL NETWORK**\n",
        "\n",
        "Did not work very well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APCSUjCSR-qA"
      },
      "source": [
        "# Normalize image vectors\n",
        "X = X/255.0\n",
        "\n",
        "model = Sequential()\n",
        "# conv layer\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # converts our 3D feature vectors to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(classSize))  # our output layer. \n",
        "# Softmax for probability distribution\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # what to track"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTyCtbovIaz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c285811-ca28-43c0-c6b5-33d28c71247d"
      },
      "source": [
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y = np.array(y)\n",
        "model.fit(X, y, batch_size=32, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "78/78 [==============================] - 12s 125ms/step - loss: 4.2050 - accuracy: 0.0093\n",
            "Epoch 2/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 4.0768 - accuracy: 0.0291\n",
            "Epoch 3/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 3.8147 - accuracy: 0.0709\n",
            "Epoch 4/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 3.3075 - accuracy: 0.1504\n",
            "Epoch 5/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 2.9634 - accuracy: 0.2087\n",
            "Epoch 6/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 2.4837 - accuracy: 0.3041\n",
            "Epoch 7/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 2.1661 - accuracy: 0.3804\n",
            "Epoch 8/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 1.9116 - accuracy: 0.4351\n",
            "Epoch 9/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 1.7307 - accuracy: 0.4797\n",
            "Epoch 10/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 1.4904 - accuracy: 0.5290\n",
            "Epoch 11/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 1.4133 - accuracy: 0.5729\n",
            "Epoch 12/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 1.2176 - accuracy: 0.6248\n",
            "Epoch 13/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 1.0882 - accuracy: 0.6512\n",
            "Epoch 14/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 0.9754 - accuracy: 0.6794\n",
            "Epoch 15/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 0.9269 - accuracy: 0.7198\n",
            "Epoch 16/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 0.8277 - accuracy: 0.7404\n",
            "Epoch 17/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 0.7487 - accuracy: 0.7713\n",
            "Epoch 18/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 0.6916 - accuracy: 0.7741\n",
            "Epoch 19/20\n",
            "78/78 [==============================] - 9s 111ms/step - loss: 0.6925 - accuracy: 0.7721\n",
            "Epoch 20/20\n",
            "78/78 [==============================] - 9s 112ms/step - loss: 0.6743 - accuracy: 0.7937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f099d04c050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhl0F9bTgb3I"
      },
      "source": [
        "**RESNET50**\n",
        "\n",
        "Implementation inspiration from\n",
        "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
        "- Francois Chollet's GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKy4KiJ2gfXG"
      },
      "source": [
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # Skips over 3 hidden layers\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "        \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Add shortcut value to main path\n",
        "    X = Add()([X,X_shortcut])\n",
        "    # pass it through a RELU activation\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-aHIVMhz38"
      },
      "source": [
        "# GRADED FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Extract Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value as shortcut\n",
        "    X_shortcut = X\n",
        "\n",
        "    # MAIN PATH #\n",
        "\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # SHORTCUT PATH #\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Add shortcut value to main path\n",
        "    X = Add()([X, X_shortcut])\n",
        "    # pass through RELU activation\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZGeuXbh6yX"
      },
      "source": [
        "# GRADED FUNCTION: ResNet50\n",
        "# returns resnet model\n",
        "def ResNet50(input_shape, classes):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    # Zero-Padding, pads the input with pad(3,3)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D((2, 2), padding='same')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvrjB8aiR2F"
      },
      "source": [
        "model = ResNet50(input_shape = (IMG_SIZE, IMG_SIZE, 1), classes = classSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzYSxKstijwg"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi04Iu8wimtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87e4295-ef3f-4076-b280-a3e44404dbc9"
      },
      "source": [
        "# Normalize image vectors\n",
        "X = X/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "y = convert_to_one_hot(y, classSize).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X.shape[0]))\n",
        "print (\"X shape: \" + str(X.shape))\n",
        "print (\"y shape: \" + str(y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 2480\n",
            "X shape: (2480, 100, 100, 1)\n",
            "y shape: (2480, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TjULdxKjEQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3584780-1552-467a-914b-be5e9d85008e"
      },
      "source": [
        "# model.fit(X, y, epochs = 6, batch_size = 32)\n",
        "model.fit(X, y, batch_size=32, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "78/78 [==============================] - 25s 231ms/step - loss: 11.2854 - accuracy: 0.0259\n",
            "Epoch 2/20\n",
            "78/78 [==============================] - 17s 218ms/step - loss: 5.1499 - accuracy: 0.0564\n",
            "Epoch 3/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 3.6131 - accuracy: 0.1411\n",
            "Epoch 4/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 3.0828 - accuracy: 0.2512\n",
            "Epoch 5/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 2.4039 - accuracy: 0.3451\n",
            "Epoch 6/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 1.9473 - accuracy: 0.4875\n",
            "Epoch 7/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 1.4202 - accuracy: 0.5808\n",
            "Epoch 8/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 1.1359 - accuracy: 0.6709\n",
            "Epoch 9/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 0.9673 - accuracy: 0.7104\n",
            "Epoch 10/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 0.9160 - accuracy: 0.7131\n",
            "Epoch 11/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 0.7013 - accuracy: 0.7831\n",
            "Epoch 12/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 0.8402 - accuracy: 0.7702\n",
            "Epoch 13/20\n",
            "78/78 [==============================] - 17s 218ms/step - loss: 0.7154 - accuracy: 0.7980\n",
            "Epoch 14/20\n",
            "78/78 [==============================] - 17s 219ms/step - loss: 0.8474 - accuracy: 0.7627\n",
            "Epoch 15/20\n",
            "78/78 [==============================] - 17s 218ms/step - loss: 0.6396 - accuracy: 0.8350\n",
            "Epoch 16/20\n",
            "78/78 [==============================] - 17s 217ms/step - loss: 0.7507 - accuracy: 0.7753\n",
            "Epoch 17/20\n",
            "78/78 [==============================] - 17s 217ms/step - loss: 0.4161 - accuracy: 0.8828\n",
            "Epoch 18/20\n",
            "78/78 [==============================] - 17s 217ms/step - loss: 0.3210 - accuracy: 0.9047\n",
            "Epoch 19/20\n",
            "78/78 [==============================] - 17s 217ms/step - loss: 0.1732 - accuracy: 0.9531\n",
            "Epoch 20/20\n",
            "78/78 [==============================] - 17s 217ms/step - loss: 0.1548 - accuracy: 0.9536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f099d07d510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGpWB9xYOAbL"
      },
      "source": [
        "Resnet model did not performed well compared to sequential model when image size was ~ (30 X 30) but outperformed it when it was increased to ~(100 X 100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1bCfeTMhb5h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}